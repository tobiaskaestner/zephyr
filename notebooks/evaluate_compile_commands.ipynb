{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_files=sorted(Path('../../twister-out').glob('**/compile_commands.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Found {len(list_of_files)} different applications\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import subprocess\n",
    "# Regular expression to match the directory name after \"twister-out\", considering potential trailing slash\n",
    "pattern = r\"twister-out/(?P<platform>[^/]*)/(?P<test_dir>.*)/compile_commands.json\"  # Added optional trailing slash to handle both cases\n",
    "\n",
    "header_pattern = r\"\"\n",
    "c_files = []\n",
    "\n",
    "WORKSPACE_DIR=Path('../../').resolve()\n",
    "print(WORKSPACE_DIR)\n",
    "counter=1\n",
    "\n",
    "for f in list_of_files:\n",
    "    \n",
    "    file_path = str(f.resolve())\n",
    "\n",
    "    # Use re.search to find the match\n",
    "    match = re.search(pattern, file_path)\n",
    "\n",
    "    # Extract the target directory name if there is a match\n",
    "    if match:\n",
    "     platform_name = match.group(\"platform\")\n",
    "     test_suite_dir = match.group(\"test_dir\")\n",
    "    else:\n",
    "     continue\n",
    "\n",
    "    print(f\"Looking at {platform_name} - {test_suite_dir} ({counter}/{len(list_of_files})\")\n",
    "    counter = counter + 1\n",
    "    \n",
    "    f = f.resolve()\n",
    "\n",
    "    with open(f,\"r\") as text:\n",
    "        data = json.load(text)\n",
    "\n",
    "        # each data is a single invocation of the C compiler, the 'file' attribute holds the name of the c-file that is compiled\n",
    "        h_files = []\n",
    "        for d in data:\n",
    "            if(d['file'].endswith('empty_file.c')):\n",
    "                continue\n",
    "            \n",
    "            p=Path(d['file'])\n",
    "\n",
    "            c_files.append([platform_name, \n",
    "                            test_suite_dir, \n",
    "                            str(p.relative_to(Path('../..' ).resolve())) ])\n",
    "            command = f\"ninja -C {f.parent} -t deps {d['output']}\".split()\n",
    "            \n",
    "            result = subprocess.run(command, capture_output=True, text=True)\n",
    "            \n",
    "            for line in result.stdout.splitlines():\n",
    "                if line.endswith(\".h\"):\n",
    "                    if line.strip() not in h_files:\n",
    "                        h_files.append(line.strip())                        \n",
    "                        h_path = Path(line.strip()).absolute()\n",
    "                        \n",
    "                        c_files.append([platform_name, \n",
    "                                        test_suite_dir, \n",
    "                                        str(h_path.relative_to(WORKSPACE_DIR) ) ])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(c_files, columns = ['platform', 'test_name', 'file'])\n",
    "df.to_csv('cortex-m_kernel_tests_and_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "files=df['file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "files=files.drop_duplicates()\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "files.to_csv('cortex-m_kernel_tests_and_samples_unique_files.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "platform='mps2_an385'\n",
    "test_name='samples/basic/minimal/sample.minimal.no-mt-no-timers.arm'\n",
    "filter = (df['platform'].str.startswith(platform)) & (df['test_name'].str.startswith(test_name))\n",
    "\n",
    "unique_files = df[filter].drop_duplicates(subset='file')\n",
    "\n",
    "unique_files.file[unique_files.file.str.startswith('zephyr/')].sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_files[unique_files['file'].str.startswith('zephyr/')].sort_values(by='file').to_csv('qemu_cortex_m3_hello_world_samples_intree_files.csv',columns=['file'], index=False)\n",
    "unique_files.sort_values(by='file').to_csv('qemu_cortex_m3_hello_world_samples_intree_files.csv',columns=['file'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.test_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
